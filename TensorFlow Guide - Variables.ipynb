{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"1.10.0\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using TensorFlow\n",
    "tf_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "\n",
    "A TensorFlow **variable** is the best way to represent shared, persistent state\n",
    "manipulated by your program.\n",
    "\n",
    "Variables are manipulated via the `Variable` class. A `Variable`\n",
    "represents a tensor whose value can be changed by running ops on it. Unlike\n",
    "`Tensor` objects, a `Variable` exists outside the context of a single\n",
    "`run` call.\n",
    "\n",
    "Internally, a `Variable` stores a persistent tensor. Specific ops allow you\n",
    "to read and modify the values of this tensor. These modifications are visible\n",
    "across multiple `Session`s, so multiple workers can see the same values for a\n",
    "`Variable`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Variable\n",
    "\n",
    "The best way to create a variable is to call the `get_variable`\n",
    "function. This function requires you to specify the `Variable`'s name. This name\n",
    "will be used by other replicas to access the same variable, as well as to name\n",
    "this variable's value when checkpointing and exporting models. `get_variable`\n",
    "also allows you to reuse a previously created variable of the same name, making it\n",
    "easy to define models which reuse layers.\n",
    "\n",
    "To create a variable with `get_variable`, simply provide the name, shape and dtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable{Float32}(<Tensor my_variable:1 shape=(1, 2, 3) dtype=Float32>, <Tensor my_variable/Assign:1 shape=(1, 2, 3) dtype=Float32>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_variable = get_variable(\"my_variable\", [1,2,3], Float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a variable named \"my_variable\" which is a three-dimensional tensor\n",
    "with shape `[1, 2, 3]` and dtype `Float32`. Its initial value will be randomized via\n",
    "`TensorFlow.Variables.NormalInitializer`.\n",
    "\n",
    "Usually the `Variable`'s name is the same as the name of the object we choose to reference the `Variable`, as in the previous example. TensorFlow.jl provides a syntatic sugar for this pattern using the `@tf` macro:\n",
    "\n",
    "```julia\n",
    "@tf my_variable = get_variable([1,2,3], Float32) # same as the definition above\n",
    "```\n",
    "\n",
    "The macro also works on any assignment expression where the right hand side is a `Tensor`. For example, `@tf i = constant(1)` is the same as writing `i = constant(1, name=\"i\")`.\n",
    "\n",
    "You may optionally specify the initializer to `get_variable`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable{Int64}(<Tensor my_int_variable:1 shape=(1, 2, 3) dtype=Int64>, <Tensor my_int_variable/Assign:1 shape=(1, 2, 3) dtype=Int64>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf my_int_variable = get_variable([1,2,3], Int64; initializer=ConstantInitializer(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When initialized, all cells of `my_int_variable` will be zero. You may also pass any univariate distributions from Distributions.jl as the initializer.\n",
    "\n",
    "**⋆Note**: Initialization using the value of another `Tensor` is not yet supported in TensorFlow.jl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable collections\n",
    "\n",
    "Because disconnected parts of a TensorFlow program might want to create\n",
    "variables, it is sometimes useful to have a single way to access all of\n",
    "them. For this reason TensorFlow provides **collections**, which are named lists\n",
    "of tensors or other objects, such as `Variable` instances.\n",
    "\n",
    "By default every `Variable` gets placed in the following two collections in the default graph:\n",
    "\n",
    " * `Variables` --- all defined variable.\n",
    " * `TrainableVariables` --- variables for which TensorFlow will\n",
    "   calculate gradients.\n",
    "\n",
    "To retrieve a list of all the variables (or other objects) you've placed in a collection you can use `get_collection`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = get_collection(:Variables)\n",
    "trainable_vars = get_collection(:TrainableVariables);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want a variable to be trainable, specify `trainable=false` as a keyword argument to `get_variable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "false\n"
     ]
    }
   ],
   "source": [
    "@tf my_non_trainable = get_variable([], Float32; trainable=false)\n",
    "println(my_non_trainable in vars)\n",
    "println(my_non_trainable in trainable_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**⋆Note**: Unlike the Python API, TensorFlow.jl does not keep separate `GLOBAL_VARIABLES` and `LOCAL_VARIABLES` collections.\n",
    "\n",
    "You can also use your own collections. Any `Symbol` is a valid collection name,\n",
    "and there is no need to explicitly create a collection. To add a variable (or\n",
    "any other object) to a collection after creating the variable, call\n",
    "`TensorFlow.add_to_collection`.  For example, the following code adds an existing\n",
    "variable named `my_local` to a collection named `my_collection_name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf my_local = get_variable([], Float64)\n",
    "TensorFlow.add_to_collection(:my_collection, my_local)\n",
    "my_local in get_collection(:my_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device placement [WIP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing variables\n",
    "\n",
    "Before you can use a variable, it must be initialized. If you are programming in\n",
    "the low-level TensorFlow API (that is, you are explicitly creating your own\n",
    "graphs and sessions), you must explicitly initialize the variables.  Most\n",
    "high-level frameworks such as `contrib.slim`, `estimator.Estimator` and\n",
    "`Keras` automatically initialize variables for you before training a model.\n",
    "\n",
    "Explicit initialization is otherwise useful because it allows you not to rerun\n",
    "potentially expensive initializers when reloading a model from a checkpoint as\n",
    "well as allowing determinism when randomly-initialized variables are shared in a\n",
    "distributed setting.\n",
    "\n",
    "To initialize all trainable variables in one go, before training starts, call\n",
    "`global_variables_initializer()`. This function returns a single operation\n",
    "responsible for initializing all variables in the\n",
    "`Variables` collection. Running this operation initializes\n",
    "all variables. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-04 13:50:20.654869: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "sess = Session()\n",
    "run(sess, global_variables_initializer())\n",
    "# Now all variables are initialized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do need to initialize variables yourself, you can run the variable's initializer operation via its assign node. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(sess, my_variable.assign_node);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**⋆Note**: `report_unitialized_variables` and `initialized_value` not yet supported in TensorFlow.jl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Variables\n",
    "\n",
    "To use the value of a `Variable` in a TensorFlow graph, simply treat it like\n",
    "a normal `Tensor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor Add:1 shape=() dtype=Float64>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf v = get_variable([], Float64; initializer=ConstantInitializer(0.0))\n",
    "w = v + 1 # w is a Tensor which is computed based on the value of v.\n",
    "          # Any time a variable is used in an expression it gets automatically\n",
    "          # converted to a Tensor representing its value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assign a value to a variable, use the methods `assign`, `assign_add`, and\n",
    "friends in the `Variable` class. For example, here is how you can call these\n",
    "methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignment = assign_add(v, 1)\n",
    "run(sess, global_variables_initializer())\n",
    "run(sess, assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most TensorFlow optimizers have specialized ops that efficiently update the\n",
    "values of variables according to some gradient descent-like algorithm. See\n",
    "`train.Optimizer` for an explanation of how to use optimizers.\n",
    "\n",
    "**⋆Note**: `read_value` not yet supported by TensorFlow.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow supports two ways of sharing variables:\n",
    "\n",
    " * Explicitly passing `Variable` objects around.\n",
    " * Implicitly wrapping `Variable` objects within `variable_scope` objects.\n",
    "\n",
    "While code which explicitly passes variables around is very clear, it is\n",
    "sometimes convenient to write TensorFlow functions that implicitly use\n",
    "variables in their implementations. Most of the functional layers from\n",
    "`layers` use this approach, as well as all `metrics`, and a few other\n",
    "library utilities.\n",
    "\n",
    "Variable scopes allow you to control variable reuse when calling functions which\n",
    "implicitly create and use variables. They also allow you to name your variables\n",
    "in a hierarchical and understandable way.\n",
    "\n",
    "For example, let's say we write a function to create a convolutional / relu\n",
    "layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conv_relu (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions: Normal\n",
    "\n",
    "function conv_relu(input, kernel_shape, bias_shape)\n",
    "    # Create variable named \"weights\"\n",
    "    @tf weights = get_variable(kernel_shape, Float64; initializer=Normal())\n",
    "    # Create variable named \"biases\"\n",
    "    @tf biases = get_variable(bias_shape, Float64; initializer=ConstantInitializer(0.0))\n",
    "    conv = nn.conv2d(input, weights, [1,1,1,1], \"SAME\")\n",
    "    return nn.relu(conv + biases)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses short names `weights` and `biases`, which is good for\n",
    "clarity. In a real model, however, we want many such convolutional layers, and\n",
    "calling this function repeatedly would not work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor Relu:1 shape=(1, 10, 10, 32) dtype=Float64>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = random_normal([1,10,10,32])\n",
    "input2 = random_normal([1,20,20,32])\n",
    "x = conv_relu(input1, [5,5,32,32], [32])\n",
    "# x = conv_relu(x, [5,5,32,32], [32]) # This fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the desired behavior is unclear (create new variables or reuse the\n",
    "existing ones?) TensorFlow will fail. Calling `conv_relu` in different scopes,\n",
    "however, clarifies that we want to create new variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_image_filter (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function my_image_filter(input_images)\n",
    "    variable_scope(\"conv1\") do\n",
    "        # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "        global relu1 = conv_relu(input_images, [5,5,32,32], [32])\n",
    "    end\n",
    "    variable_scope(\"conv2\") do\n",
    "        # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n",
    "        return conv_relu(relu1, [5,5,32,32], [32])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do want the variables to be shared, you can create a scope with the same name using `reuse=true`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor Relu_5:1 shape=(1, 20, 20, 32) dtype=Float64>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_scope(\"model\") do\n",
    "    output1 = my_image_filter(input1)\n",
    "end\n",
    "variable_scope(\"model\", reuse=true) do\n",
    "    output2 = my_image_filter(input2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**⋆Note**: `scope.reuse_variables` and passing exising scopes to `variable_scope` not yet supported by TensorFlow.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "*Except as otherwise noted, the content of this page is licensed under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/), and code samples are licensed under the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0). This notebook is adapted from the official [TensorFlow Guide on Variables](https://www.tensorflow.org/guide/variables).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
